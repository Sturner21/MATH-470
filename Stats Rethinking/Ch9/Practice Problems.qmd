---
title: "Practice Problems"
format: html
---

# Load Libraries

```{r}
library(tidyverse)
library(rethinking)
```

# 9E1

Which of the following is a requirement of the simple Metropolis algorithm?

1.  The parameters must be discrete
2.  The likelihood function must be Gaussian
3.  Th proposal distribution must be symmetric

1 definitely must be true. 2 I would say not. And 3 is probably not.

# 9E2

Gibbs sampling is more efficient than the Metropolis algorithm. How does it achieve this extra efficiency? Are there any limitations to the Gibbs sampling strategy?

It is more efficient because it uses adaptive proposals from conjugate pairs. It runs into problems because it has a high concentration of measure, meaning it has a had time exploring without going wildly in the wrong direction.

# 9E3

Which sort of parameters can Hamiltonian Monte Carlo not handle? Can you explain why?

The HMC cannot handle discrete parameters, since it must be able to stop anywhere along gradient it travels.

# 9E4

Explain the difference between the effective number of samples, `n_eff` as calculated by Stan, and the actual number of samples.

The effective number of samples is an estimate of the number of independent samples from the posterior distribution, in terms of some estimating some function like the posterior mean. However, since Markov chains are often correlated this will decreased the amount of independent samples. Thus, Stan provides a calculated amount of independent samples depending on the level of autocorrelation.

# 9E5

Which value should `Rhat` approach, when a chain is sampling the posterior distribution correctly?

$\hat{R}$ should approach 1.

# 9E6

Sketch a good trace plot for a Markov chain, one that is effectively sampling from the posterior distribution. What is good about its shape? Then sketch a trace plot for malfunctioning Markov chain. What about its shape indicates malfunction?

A good chain is one that is:

1.  Stationary - The path of the chain says within the same high-probability proportion of the posterior distribution
2.  Mixing well - Chain rapidly explores the full region
3.  Converging - Multiple chains stick around the same region of high probability

Violating any of these will result in a bad chain

# 9E7

Repeat the problem above but this time for a trace rank plot.

The trank plot simply reduces the noise of a trace plot into a single line. Therefore the same conditions and looks as described above hold

# 9M1

Re-estimate the terrain ruggedness model from the chapter but now use a uniform prior for the standard deviation, `sigma`. The uniform prior should be `dunif(0,1)`. Use `ulam` to estimate the posterior. Does the different prior have any detectable influence on the posterior distribution of `sigma`? Why or why not?

```{r}
#Set up for model
data("rugged")
d <- rugged
d$log_gdp <- log(d$rgdppc_2000)
dd <- d[complete.cases(d$rgdppc_2000),]
dd$log_gdp_std <- dd$log_gdp / mean(dd$log_gdp)
dd$rugged_std <- dd$rugged / max(dd$rugged)
dd$cid <- ifelse(dd$cont_africa==1, 1, 2)

dat_slim <- list(
  log_gdp_std = dd$log_gdp_std,
  rugged_std = dd$rugged_std,
  cid = as.integer(dd$cid)
)

#Run model
m9.1 <- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- a[cid] + b[cid]*(rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ), data=dat_slim, chains=1
)
```

```{r}
#Let's examine down here so we don't rerun that process a ton, it took a LONG time
precis(m9.1, depth=2)
```

```{r}
#Now we can do the problem
m9M1 <- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- a[cid] + b[cid]*(rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dunif(0,1)
  ), data=dat_slim, chains=1
)
```

```{r}
precis(m9M1, depth=2)
```

This did not appear to have an effect on `sigma`. My guess would be that there is so much data that this change to a flat prior simply got overridden by the data.

# 9M2

Modify the terrain ruggedness model again. This time, change the prior for `b[cid]` to `dexp(0.3)`. What does this do to the posterior distribution? Can you explain it?

```{r}
m9M2 <- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- a[cid] + b[cid]*(rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dexp(0.3),
    sigma ~ dunif(0,1)
  ), data=dat_slim, chains=1
)
```

```{r}
precis(m9M2, depth=2)
```

This lessened our estimated effect of `b[2]` considerable from -0.14 to 0.02. Meanwhile, almost all other values remained the same. This should mean that our guess for the prior would have a large influence on the output of `b[2]` possibly suggesting the estimates aren't very good for it.

# 9M3

Re-estimate one of the Stan models from the chapter, but at different number of `warmup iterations`. Be sure to use the same number of sampling iterations in each case. Compare the `n_eff` values. How much warm-up is enough?

```{r}
#Recreate m9.1 but change warmup iterations

m9M3 <- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- a[cid] + b[cid]*(rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ), data=dat_slim, chains=1, warmup = 900
)
```

```{r}
precis(m9M3, depth=2)
```

With 900 warm-ups we start to see that our `n_eff` value drops off sharply. As the textbook explains, we only need about 200 and for the most part our observations are falling around that range so it's not impacting out model too much. However, with much more then we will probably start to see this model begin to deteriorate.

```{r}
m9M3.2 <- ulam(
  alist(
    log_gdp_std ~ dnorm(mu, sigma),
    mu <- a[cid] + b[cid]*(rugged_std - 0.215),
    a[cid] ~ dnorm(1, 0.1),
    b[cid] ~ dnorm(0, 0.3),
    sigma ~ dexp(1)
  ), data=dat_slim, chains=1, warmup = 100
)
```

```{r}
precis(m9M3.2, depth=2)
```

In contrast here we only give the model 100 to warm up. This drastically increases our `n_eff` value and doesn't seem to effect our $\hat{R}$ value much, if at all. Thus, for this model it seems that we could get away with having much less warm-up than the model uses.

# 9H1\*

Run the model below and then inspect the posterior distribution and explain what it is accomplishing.

Compare this samples for the parameters `a` and `b`. Can you explain the different trace plots? If you are unfamiliar with Cauchy distribution, you should look it up. The key feature to attend to is that it has no expected value/ Can you connect this fact to the trace plot?

```{r}
#Cell provided for problem

mp <- ulam(
  alist(
    a ~ dnorm(0,1),
    b ~ dcauchy(0,1)
  ), data=list(y=1), chains=1
)
```

```{r}
precis(mp, depth=2)
```

```{r}
traceplot(mp)
```

I'm not going to lie, I have no idea what this is doing or trying to accomplish. It also does look like for `b` that there is an expected value that it settles to, at least for this run.

# 9H2

# 9H3

# 9H4

# 9H5

Modify the Metropolis algorithm code from the chapter to handle the case that the island populations have a different distribution than the island labels. This means that the island's number will not be the same as its population.

# 9H6

# 9H7
